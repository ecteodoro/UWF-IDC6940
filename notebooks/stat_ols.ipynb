{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ordinary Least Squares Regression\n",
    "\n",
    "This notebook demonstrates how to perform Ordinary Least Squares (OLS) regression using the `statsmodels` library in Python. We will fit a linear regression model to the cherry blossom dataset and interpret the results.\n"
   ],
   "id": "a825ddd0bfff59b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Plan and assumptions\n",
    "\n",
    "- Use all available predictors except `year` and `bloom_day` as features.\n",
    "- Use years 1921–2015 as the pool for training/validation. The user requested an \"80/10 split\"; that seems underspecified, so I assume a sequential 80/20 split (train/validation) within 1921–2015 to keep time order.\n",
    "- Reserve 2016–2025 as the test set and report performance on that set.\n",
    "- Metrics: RMSE, MAE, and WMAPE (defined here as sum(|error|) / sum(|actual|)).\n"
   ],
   "id": "ad42181748d90936"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:32:13.036902Z",
     "start_time": "2025-11-19T04:32:11.911275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "sns.set(style='whitegrid')\n"
   ],
   "id": "16b088eafadba3e5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1) Load data",
   "id": "285d659ef20cce85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:32:13.055012Z",
     "start_time": "2025-11-19T04:32:13.043191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_PATH = '../data/cherry_blossom_data.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Loaded rows:', len(df))\n",
    "df.head()\n"
   ],
   "id": "ed55ef5cd73625ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   year  days_dec_ge_45  days_jan_ge_45  days_feb_ge_45  prec_winter  \\\n",
       "0  1921              30              24              23         3.41   \n",
       "1  1922              20              17              19         2.56   \n",
       "2  1923              18              15              14         3.12   \n",
       "3  1924              25              22              25         3.68   \n",
       "4  1925              16              12              14         2.89   \n",
       "\n",
       "   mean_temp_winter  surface_temp_chg  climate_incidents  bloom_day  \n",
       "0              42.8             -0.05                  3         79  \n",
       "1              39.1             -0.12                  2         97  \n",
       "2              36.4             -0.18                  1         99  \n",
       "3              43.2             -0.09                  4        104  \n",
       "4              36.8             -0.14                  2         86  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>days_dec_ge_45</th>\n",
       "      <th>days_jan_ge_45</th>\n",
       "      <th>days_feb_ge_45</th>\n",
       "      <th>prec_winter</th>\n",
       "      <th>mean_temp_winter</th>\n",
       "      <th>surface_temp_chg</th>\n",
       "      <th>climate_incidents</th>\n",
       "      <th>bloom_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1921</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>3.41</td>\n",
       "      <td>42.8</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1922</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>2.56</td>\n",
       "      <td>39.1</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1923</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>3.12</td>\n",
       "      <td>36.4</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1924</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>3.68</td>\n",
       "      <td>43.2</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1925</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>2.89</td>\n",
       "      <td>36.8</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2) Prepare features and target",
   "id": "eac1270c25f7b0ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:32:13.081007Z",
     "start_time": "2025-11-19T04:32:13.077818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure numeric types\n",
    "numeric_cols = ['days_dec_ge_45','days_jan_ge_45','days_feb_ge_45','prec_winter',\n",
    "                'mean_temp_winter','surface_temp_chg','climate_incidents']\n",
    "for c in numeric_cols + ['bloom_day','year']:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Drop rows with missing essential values\n",
    "df = df.dropna(subset=['year','bloom_day'] + numeric_cols).reset_index(drop=True)\n",
    "\n",
    "# Features and target\n",
    "FEATURES = numeric_cols\n",
    "TARGET = 'bloom_day'\n"
   ],
   "id": "9c8bc8b4d04c98ac",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3) Create train / validation / test splits",
   "id": "7a565f31ea0e7cd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:32:13.101369Z",
     "start_time": "2025-11-19T04:32:13.098559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training/validation pool: 1921-2015 (inclusive)\n",
    "train_val_df = df[(df['year'] >= 1921) & (df['year'] <= 2015)].sort_values('year').reset_index(drop=True)\n",
    "# Test set: 2016-2025\n",
    "test_df = df[(df['year'] >= 2016) & (df['year'] <= 2025)].sort_values('year').reset_index(drop=True)\n",
    "\n",
    "print(f'Train/Val rows: {len(train_val_df)}, Test rows: {len(test_df)}')\n",
    "\n",
    "# Sequential split (time-ordered) within train_val: 80% train, 20% val\n",
    "n = len(train_val_df)\n",
    "if n == 0:\n",
    "    raise ValueError('No data in 1921-2015 range to train/validate on.')\n",
    "train_n = int(np.floor(n * 0.8))\n",
    "train_df = train_val_df.iloc[:train_n].reset_index(drop=True)\n",
    "val_df = train_val_df.iloc[train_n:].reset_index(drop=True)\n",
    "\n",
    "print(f'Train rows: {len(train_df)}, Val rows: {len(val_df)}')\n"
   ],
   "id": "6f0daaf3f54be047",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val rows: 97, Test rows: 10\n",
      "Train rows: 77, Val rows: 20\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4) Fit OLS on training data",
   "id": "d29d71f06c159f49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:32:13.130726Z",
     "start_time": "2025-11-19T04:32:13.124171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train_df[FEATURES]\n",
    "y_train = train_df[TARGET]\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "ols_model = sm.OLS(y_train, X_train_const).fit()\n",
    "print(ols_model.summary())\n"
   ],
   "id": "5900c2a0159e85c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              bloom_day   R-squared:                       0.129\n",
      "Model:                            OLS   Adj. R-squared:                  0.041\n",
      "Method:                 Least Squares   F-statistic:                     1.460\n",
      "Date:                Tue, 18 Nov 2025   Prob (F-statistic):              0.196\n",
      "Time:                        23:32:13   Log-Likelihood:                -255.14\n",
      "No. Observations:                  77   AIC:                             526.3\n",
      "Df Residuals:                      69   BIC:                             545.0\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                99.7447     26.896      3.708      0.000      46.088     153.401\n",
      "days_dec_ge_45        0.2148      0.194      1.106      0.272      -0.172       0.602\n",
      "days_jan_ge_45        0.0332      0.255      0.130      0.897      -0.476       0.543\n",
      "days_feb_ge_45       -0.0798      0.477     -0.168      0.867      -1.031       0.871\n",
      "prec_winter           0.2095      0.600      0.349      0.728      -0.987       1.406\n",
      "mean_temp_winter     -0.2116      1.015     -0.209      0.835      -2.236       1.813\n",
      "surface_temp_chg     -8.4049      3.857     -2.179      0.033     -16.100      -0.710\n",
      "climate_incidents    -0.0064      0.149     -0.043      0.966      -0.304       0.292\n",
      "==============================================================================\n",
      "Omnibus:                        4.161   Durbin-Watson:                   1.940\n",
      "Prob(Omnibus):                  0.125   Jarque-Bera (JB):                3.966\n",
      "Skew:                          -0.554   Prob(JB):                        0.138\n",
      "Kurtosis:                       2.900   Cond. No.                     1.77e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.77e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5) Validation diagnostics (optional)",
   "id": "b237a78fe16d43df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:32:13.149610Z",
     "start_time": "2025-11-19T04:32:13.145758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_val = val_df[FEATURES]\n",
    "y_val = val_df[TARGET]\n",
    "val_pred = ols_model.predict(sm.add_constant(X_val))\n",
    "\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "val_mae = mean_absolute_error(y_val, val_pred)\n",
    "val_wmape = np.sum(np.abs(y_val - val_pred)) / np.sum(np.abs(y_val))\n",
    "\n",
    "print('Validation RMSE: {:.3f}'.format(val_rmse))\n",
    "print('Validation MAE: {:.3f}'.format(val_mae))\n",
    "print('Validation WMAPE: {:.3%}'.format(val_wmape))\n"
   ],
   "id": "918b5f76cc2521bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 6.635\n",
      "Validation MAE: 5.136\n",
      "Validation WMAPE: 5.638%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6) Evaluate on test set (2016-2025)",
   "id": "b34a6f1874231361"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:32:13.166508Z",
     "start_time": "2025-11-19T04:32:13.163141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if len(test_df) == 0:\n",
    "    print('No test data available for 2016-2025 range.')\n",
    "else:\n",
    "    X_test = test_df[FEATURES]\n",
    "    y_test = test_df[TARGET]\n",
    "    X_test_const = sm.add_constant(X_test)\n",
    "    y_pred_test = ols_model.predict(X_test_const)\n",
    "\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    test_wmape = np.sum(np.abs(y_test - y_pred_test)) / np.sum(np.abs(y_test))\n",
    "\n",
    "    print('\\nTest set performance (2016-2025)')\n",
    "    print('Rows:', len(test_df))\n",
    "    print('RMSE: {:.3f}'.format(test_rmse))\n",
    "    print('MAE: {:.3f}'.format(test_mae))\n",
    "    print('WMAPE: {:.3%}'.format(test_wmape))\n"
   ],
   "id": "de1873eb4cee59e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set performance (2016-2025)\n",
      "Rows: 10\n",
      "RMSE: 5.939\n",
      "MAE: 4.601\n",
      "WMAPE: 5.426%\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7) Plot actuals (blue) vs forecasts (red) on the test set",
   "id": "12c999ec2c17970e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a combined plot: actuals from the full dataset and forecasts overlay for 2016+\n",
    "full_years = df['year']\n",
    "full_actuals = df[TARGET]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(full_years, full_actuals.values, marker='o', color='tab:blue', label='Actual (since 1921)')\n",
    "\n",
    "if len(test_df) > 0:\n",
    "    plt.plot(test_df['year'], y_pred_test, marker='o', color='tab:red', label='Forecast (2016-2025)')\n",
    "    plt.axvline(2016, color='k', linestyle='--', linewidth=1, label='Forecast start (2016)')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Bloom Day')\n",
    "plt.title('Actual vs Forecast - Full Series with Forecasts (2016-2025)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "9fc611889a9129ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8) Notes and next steps\n",
    "\n",
    "- We fit a simple linear OLS model using all provided numeric predictors. The model summary above shows coefficients, p-values, and overall fit statistics (R-squared, etc.).\n",
    "- If you want improved predictive performance, consider: feature engineering, regularization (Ridge/Lasso), tree-based models, or time-series models that explicitly model temporal dependence.\n",
    "- I assumed an 80/20 sequential split for train/validation inside 1921–2015 to preserve time ordering. If you prefer a different split (e.g., 80/10/10 or cross-validation), tell me and I will update the notebook.\n"
   ],
   "id": "ab529c008dde7d5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
